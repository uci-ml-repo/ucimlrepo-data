{
    "datasetID": 1,
    "supportID": "DADF30A5DFEF6884474A042F87A34277E06C174B",
    "rexaID": "f7fdf9dbb5f98a218956025550c1f603b3cb24f2",
    "author": "Alexander G. Gray and Bernd Fischer and Johann Schumann and Wray L. Buntine",
    "title": "Automatic Derivation of Statistical Algorithms: The EM Family and Beyond",
    "venue": "NIPS",
    "year": "2002",
    "window": "extension of our running example, integrating several features, yields a Gaussian Bayes classifier model G 2 . G 2 has been successfully tested on various standard benchmarks [1], e.g., the <b>Abalone</b> dataset. Currently, the number of expected classes has to be given in advance. Mixture models and EM. A wide range of k-Gaussian mixture models can be handled by AUTOBAYES, ranging from the simple 1D (M 1 )",
    "mykey": 2210
}