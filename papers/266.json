{
    "datasetID": 1,
    "supportID": "21293DC5F01635E96573C3E86ACA447B82345E12",
    "rexaID": "f7fdf9dbb5f98a218956025550c1f603b3cb24f2",
    "author": "Alexander G. Gray and Bernd Fischer and Johann Schumann and Wray L. Buntine",
    "title": "Automatic Derivation of Statistical Algorithms: The EM Family and Beyond",
    "venue": "NIPS",
    "year": "2002",
    "window": "\u00e3 \u00a3 . A slight extension of the model (toward several features) yields a Gaussian Bayes classifier model \u00e3 q . \u00e3 q has been successfully tested on various standard benchmarks [1], e.g., the <b>Abalone</b> dataset. Currently, the number of expected classes has to be given in advance. Mixture models and EM. A wide range of \u00e4 -Gaussian mixture models can be handled by AUTOBAYES, ranging from the simple 1D ( \u00e5 \u00a3",
    "mykey": 266
}