{
    "datasetID": 1,
    "supportID": "2E95A52FB5E9C8FF85AB2956A24AF6FCCB84CF3D",
    "rexaID": "f7fdf9dbb5f98a218956025550c1f603b3cb24f2",
    "author": "Alexander G. Gray and Bernd Fischer and Johann Schumann and Wray L. Buntine",
    "title": "Automatic Derivation of Statistical Algorithms: The EM Family and Beyond",
    "venue": "NIPS",
    "year": "2002",
    "window": "G 1 . A slight extension of the model (toward several features) yields a Gaussian Bayes classifier model G 2 . G 2 has been successfully tested on various standard benchmarks [1], e.g., the <b>Abalone</b> dataset. Currently, the number of expected classes has to be given in advance. Mixture models and EM. A wide range of k-Gaussian mixture models can be handled by AUTOBAYES, ranging from the simple 1D (M 1 )",
    "mykey": 385
}