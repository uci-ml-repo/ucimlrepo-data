{
    "ID": 439,
    "Name": "chipseq",
    "Abstract": "ChIP-seq experiments characterize protein modifications or binding at\r\nspecific genomic locations in specific samples. The machine learning\r\nproblem in these data is structured binary classification.",
    "Types": "Sequential",
    "Task": "Classification",
    "AttributeTypes": "Integer",
    "NumInstances": 4960,
    "NumAttributes": 0,
    "DateDonated": "2018-02-21",
    "MissingValues": 0,
    "URLFolder": "../machine-learning-databases/00439/",
    "URLReadme": "#",
    "HighestAccuracy": 0,
    "RelevantInfo": "These data are significant because they are among the first to provide\r\nlabels that formalize the genome-wide peak detection problem, which is\r\na very important problem for biomedical / epigenomics researchers. \r\nThese labels can be used to train and test supervised\r\npeak detection algorithms, as explained below.\r\n\r\nThe data are in problem directories such as\r\n\r\ndata/&ltSET&gt/samples/&ltGROUP&gt/&ltSAMPLE&gt/problems/&ltPROBLEM&gt\r\n\r\nEach problem directory contains two files, labels.bed (weak labels)\r\nand coverage.bedGraph.gz (inputs). \r\n\r\nEach coverage.bedGraph.gz file represents a vector of non-negative\r\ninteger count data, one entry for each genomic position in a subset of\r\nthe human genome hg19. For example\r\n\r\ndata/H3K9me3_TDH_BP/samples/tcell/ERS358697/problems/chr8:48135599-86500000/coverage.bedGraph.gz\r\n\r\nrepresents a vector defined on all genomic positions from 48135600 to\r\n86500000 on chr8 (for a particular tcell sample named ERS358697, in\r\nthe H3K9me3_TDH_BP data set). To save disk space the vectors are saved\r\nusing a run-length encoding; for example the first three lines of this\r\nfile are\r\n\r\nchr8\t48135599\t48135625\t0\r\nchr8\t48135625\t48135629\t1\r\nchr8\t48135629\t48135632\t2\r\n\r\nwhich mean that the first 26 entries of the vector are 0, the next\r\nfour entries are 1, and the following three entries are 2. Note that\r\nstart positions are 0-based but end positions are 1-based, so the\r\nfirst line means a 0 from all positions from 48135600 to 48135625\r\n(excluding the start position 48135599 for which we have no\r\ninformation).\r\n\r\nThe goal is to learn a function that takes the coverage.bedGraph.gz\r\nfile as input, and outputs a binary classification for every genomic\r\nposition. The positive class represents peaks (typically large counts)\r\nand the negative class represents background noise (typically small\r\ncounts).\r\n\r\nWeak labels are given in labels.bed files, each of which indicates\r\nseveral regions of the genome with or without peaks. For example the\r\nfile\r\n\r\ndata/H3K4me3_XJ_immune/samples/bcell/McGill0091/problems/chr1:30028082-103863906/labels.bed\r\n\r\ncontains the 6 labels below:\r\n\r\nchr1\t33111786\t33114894\tnoPeaks\r\nchr1\t33114941\t33116174\tpeakStart\r\nchr1\t33116183\t33116620\tpeakEnd\r\nchr1\t33116633\t33116755\tnoPeaks\r\nchr1\t33116834\t33118135\tpeaks\r\nchr1\t33118161\t33120163\tnoPeaks\r\n\r\nThe four labels are interpreted as follows:\r\n\r\nnoPeaks: all of the predictions in this region should be negative /\r\nbackground noise. For example the first line in the file above means\r\nthat for a vector x_i of count data from i=30028083 to i=103863906,\r\nthe desired function should predict negative / background noise\r\nf(x_i)=0 from i=33111787 to i=33114894. If positive / peaks are\r\npredicted f(x_i)=1 for any i in this region, that is counted as a\r\nfalse positive label.\r\n\r\npeakStart: there should be exactly one peak start predicted in this\r\nregion. A peak start is defined as a position i such that a peak is\r\npredicted there f(x_i)=1 but not at the previous position\r\nf(x_{i-1})=0. The exact position is unspecified; any position is fine,\r\nas long as there is only one start in the region. Predicting exactly\r\none peak start in this region results in a true positive. More starts\r\nis a false positive, and fewer starts is a false negative. For\r\nexample,\r\n\r\n [peakStart] \r\n0 0 0 1 1 1 1 -> correct.  \r\n0 0 1 1 1 1 1 -> also correct.  \r\n0 0 0 0 0 0 0 -> false negative (no peak starts).\r\n0 0 1 0 1 1 1 -> flase positive (two peak starts).\r\n\r\npeakEnd: there should be exactly one peak end predicted in this\r\nregion. A peak end is defined as a position i such that a peak is\r\npredicted there f(x_i)=1 but not at the next position f(x_{i+1})=0.\r\nThe exact position is unspecified; any position is fine, as long as\r\nthere is only one end in the region. Predicting exactly one peak end\r\nin this region results in a true positive. More ends is a false\r\npositive, and fewer ends is a false negative. For example,\r\n\r\n [ peakEnd ] \r\n1 1 1 1 0 0 0 -> correct.  \r\n1 1 1 1 1 0 0 -> also correct.  \r\n0 0 0 0 0 0 0 -> false negative (no peak ends).\r\n1 1 1 0 1 0 0 -> flase positive (two peak ends).\r\n\r\npeaks: there should be at least one peak predicted somewhere in this\r\nregion (anywhere is fine). Zero predicted peaks in this region is a\r\nfalse negative. If there is a predicted peak somewhere in this region\r\nthat is a true positive.\r\n\r\nFor a particular set of predicted peaks f(x), the total number of\r\nincorrect labels (false positives + false negatives) can be computed\r\nas an evaluation metric (smaller is better). Typically the peak\r\npredictions are also stored using a run-length encoding; the error\r\nrates can be computed using the reference implementation in R package\r\nPeakError, https://github.com/tdhock/PeakError\r\n\r\nReceiver Operating Characteristic curves can be computed for a family\r\nof predicted peaks f_lambda(x), where lambda is some significance\r\nthreshold, intercept parameter, etc. Compute the TPR and FPR as follows:\r\n\r\nTPR = (total number of true positives)/(total number of labels that could have a true positive)\r\n = (number of correct peaks, peakStart, peakEnd labels)/(number of peaks, peakStart, peakEnd labels)\r\n\r\nFPR = (total number of false positives)/(total number of labels that could have a false positive)\r\n = (\r\nnumber of peakStart/End labels with two or more predicted starts/end + \r\nnumber of noPeaks labels with predicted peaks\r\n)/(number of peakStart, peakEnd, and noPeaks labels)\r\n\r\nSuggested fold ID numbers for four-fold cross-validation experiments\r\ncan be found in data/*/folds.csv files. For example\r\ndata/H3K36me3_TDH_other/folds.csv contains\r\n\r\nproblem,fold\r\nchr16:8686921-32000000,1\r\nchr16:60000-8636921,1\r\nchr21:43005559-44632664,2\r\nchr14:19050000-107289540,3\r\nchr15:29209443-77800000,4\r\n\r\nwhich means that problems chr16:8686921-32000000 and\r\nchr16:60000-8636921 should be considered fold ID 1,\r\nchr21:43005559-44632664 should be considered fold ID 2, etc. This\r\nmeans that for data set H3K36me3_TDH_other, the fold ID 2 consists of\r\nall data in\r\ndata/H3K36me3_TDH_other/samples/*/*/problems/chr21:43005559-44632664\r\ndirectories.\r\n\r\nThere are several types of learning settings that could be used with\r\nthese data. Here are four examples.\r\n\r\nUnsupervised learning. Train models only using the\r\ncoverage.bedGraph.gz files. Only use the labels for evaluation (not\r\nfor training model parameters).\r\n\r\nSupervised learning. Train models only using the coverage.bedGraph.gz\r\nand labels.bed files in the train set. Use the labels in the test set\r\nto evaluate prediction accuracy.\r\n\r\nSemi-supervised learning. Train models using the coverage.bedGraph.gz\r\nand labels.bed files in the train set. You can additionally use the\r\ncoverage.bedGraph.gz files in the test set at training time. Use the\r\nlabels in the test set to evaluate prediction accuracy.\r\n\r\nMulti-task learning. Many data sets come from different experiment\r\ntypes, so have different peak patterns. For example H3K4me3_TDH_immune\r\nis a H3K4me3 histone modification (sharp peak pattern) and\r\nH3K36me3_TDH_immune is a H3K36me3 histone modification (broad peak\r\npattern). Therefore it is not expected that models should generalize\r\nbetween data sets. However there is something common across data sets\r\nin that in each data set, the peak / positive class is large values,\r\nwheras the noise / negative class is small values. Therefore\r\nmulti-task learning may be interesting. To compare a multi-task\r\nlearning model to a single-task learning model, use the suggested\r\ncross-validation fold IDs. For test fold ID 1, train both the\r\nmulti-task and single-task learning models using all other folds, then\r\nmake predictions on all data with fold ID 1. \r\n",
    "Source": "Toby Dylan Hocking\r\ntoby.hocking@mail.mcgill.ca\r\nMcGill University",
    "Acknowledgements": "Please cite the Bioinformatics paper above.",
    "Area": "Life",
    "RelevantPapers": "The labeling method and details on how to compute the number of incorrect labels is described in\r\n\r\nOptimizing ChIP-seq peak detectors using visual labels and supervised machine learning.\r\nToby Dylan Hocking, Patricia Goerner-Potvin, Andreanne Morin, Xiaojian Shao, Tomi Pastinen, Guillaume Bourque.\r\nBioinformatics, Volume 33, Issue 4, 15 February 2017, Pages 491\u00e2\u20ac\u201c499, https://doi.org/10.1093/bioinformatics/btw672\r\n",
    "AttributeInfo": "Each attribute is a non-negative integer representing the number DNA sequence reads that has aligned at that particular region of the genome. Larger values are more likely to be peaks / positive, smaller values are more likely to be noise / negative.",
    "FormatType": "",
    "NumHits": 0
}