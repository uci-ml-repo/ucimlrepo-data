{
    "ID": 344,
    "Name": "Heterogeneity Activity Recognition",
    "Abstract": "The Heterogeneity Human Activity Recognition (HHAR) dataset from Smartphones and Smartwatches is a dataset devised to benchmark human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc.) in real-world contexts; specifically, the dataset is gathered with a variety of different device models and use-scenarios, in order to reflect sensing heterogeneities to be expected in real deployments.",
    "Types": "Multivariate, Time-Series",
    "Task": "Classification, Clustering",
    "AttributeTypes": "Real",
    "NumInstances": 43930257,
    "NumAttributes": 16,
    "DateDonated": "2015-10-26",
    "MissingValues": 1,
    "URLFolder": "../machine-learning-databases/00344/",
    "URLReadme": "#",
    "HighestAccuracy": 0,
    "RelevantInfo": "The Heterogeneity Dataset for Human Activity Recognition from Smartphone and Smartwatch sensors consists of two datasets devised to investigate sensor heterogeneities' impacts on human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc). The datasets were used for the results and analyses produced in [1]. \nActivity recognition data set\n\nThe dataset contains the readings of two motion sensors commonly found in smartphones. Reading were recorded while users executed activities scripted in no specific order carrying smartwatches and smartphones.\nActivities: \u2018Biking\u2019, \u2018Sitting\u2019, \u2018Standing\u2019, \u2018Walking\u2019, \u2018Stair Up\u2019 and \u2018Stair down\u2019.\nSensors: Sensors: Two embedded sensors, i.e., Accelerometer and Gyroscope, sampled at the highest frequency the respective device allows.\nDevices: 4 smartwatches (2 LG watches, 2 Samsung Galaxy Gears)\n8 smartphones (2 Samsung Galaxy S3 mini, 2 Samsung Galaxy S3, 2 LG Nexus 4, 2 Samsung Galaxy S+)\nRecordings: 9 users \n\n Recording scenario\n===============\n\nThe activity recognition environment and scenario has been designed to generate many activity primitives, yet in a realistic manner. Users took 2 different routes for the biking and walking, and 2 different set of stairs were used for the stairs up and down.\n\n Still experiment data set\n===================\n\nAccelerometer recordings as above but with devices lying still, in 6 different orientations. Devices used comprise 31 smartphones, 4 smartwatches and 1 tablet, representing 13 different models from 4 manufacturers, running variants of Android and iOS.",
    "Source": "Allan Stisen, allans, '@' cs.au.dk, Aarhus University, Denmark \nHenrik Blunck, blunck '@' cs.au.dk, Aarhus University, Denmark \nSourav Bhattacharya, sourav.bhattacharya '@' bell-labs.com, Bell Laboratories, Dublin, Ireland \nThor Siiger Prentow, prentow '@' cs.au.dk, Aarhus University, Denmark \nMikkel Baun Kj\u00e6rgaard, mikkelbk '@' cs.au.dk, Aarhus University, Denmark \nAnind Dey, anind '@' cs.cmu.edu, Carnegie Mellon University, USA \nTobias Sonne,tsonne '@' cs.au.dk, Aarhus University, Denmark \nMads M\u00f8ller Jensen, mmjensen '@' cs.au.dk , Aarhus University, Denmark",
    "Acknowledgements": "Use of this dataset in publications should be acknowledged by referencing publication [1]. \nWe recommend to refer to this dataset as the \"Heterogeneity Human Activity Recognition Dataset\" or HHAR for short in publications. \nWe also appreciate if you drop us an email (allans '@' cs.au.dk or blunck \u2018@\u2019 cs.au.dk) to inform us of any publication using this dataset or if you have further question about the dataset and how to make use of it. \nReference [1] details the dataset, recording scenarios, multimodality and sensor aspects of the setup as well as quality metrics for evaluating heterogeneities and their impact on HAR.",
    "Area": "Computer",
    "RelevantPapers": "[1] Allan Stisen, Henrik Blunck, Sourav Bhattacharya, Thor Siiger Prentow, Mikkel Baun Kj\u00e6rgaard, Anind Dey, Tobias Sonne, and Mads M\u00f8ller Jensen \"Smart Devices are Different: Assessing and Mitigating Mobile Sensing Heterogeneities for Activity Recognition\" In Proc. 13th ACM Conference on Embedded Networked Sensor Systems (SenSys 2015), Seoul, Korea, 2015. http://dx.doi.org/10.1145/2809695.2809718",
    "AttributeInfo": "Activity recognition data set \naccelerometer Samples ------------ \nThe Phones_accelerometer.csv contains all smartphone accelerometer samples from all devices and users. \nThe csv file consist of the following columns: \n'Index', 'Arrival_Time', 'Creation_Time', 'x', 'y', 'z', 'User', 'Model', 'Device', 'gt' \n\nAll samples from all the experiments is a row in the file containing each column value. \n\n------------- Groundtruths -------------------- \n\nThe null class is defined as null in the gt (groundtruth) column, whereas the rest of the classes can be seen in the column. \n\n\n------------- Devices -------------------------- \nthe phones from the still experiment which has been used for activity recognition is the following: \n\u00e2\u20ac\u02dcit-116', 'it-133', 'it-108', 'it-103','it-123','3Renault-AH', 'no-name/LG-Nexus4','G-Watch' \n\nThe device numbering used in the data set is: \nLG-Nexus 4 \n'nexus4_1' \n'nexus4_2' \nSaumsung Galaxy S3 \n's3_1' \n's3_2\u00e2\u20ac\u2122 \nSamsung Galaxy S3 min: \n's3mini_1' \n's3mini_2' \nSamsung Galaxy S+: \n'samsungold_1' \n'samsungold_2' \n\nStill experiment data set \nThis is the Heterogeneity Dataset for Human Activity Recognition, and contains all the samples \nfrom the static still experiment. Where the phones where place in the 6 different possible orientation. \nThe data set is structured in the following way: \n\n------------- Static Accelerometer Samples ------------ \nEach specific device is located in the following way: Orientation/[Web Link] \nWhere the 6 different orientations can be either one of the following: \nPhoneonback,Phoneonbottom,Phoneonfront,Phoneonleft,Phoneonright,Phoneontop \n\nFor example to get the samples from the device named 3Renault-AH of the model Samsung-Galaxy-S3 Mini when laying static on the back we get the following structure: \nPhoneonback/3Renault-AH/Samsung-Galaxy-S3 Mini.csv. \n\nEach CSV file consist of 6 columns creation time, sensor time,arrival time,x,y,z. \nThe six axes from the accelerometer is the x,y,z columns. ",
    "FormatType": "Matrix",
    "NumHits": 8
}