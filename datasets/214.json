{
    "ID": 214,
    "Name": "Vicon Physical Action Data Set",
    "Abstract": "The Physical Action Data Set includes 10 normal and 10 aggressive physical actions that measure the human activity. The data have been collected by 10 subjects using the Vicon 3D tracker.",
    "Types": "Time-Series",
    "Task": "Classification",
    "AttributeTypes": "Real",
    "NumInstances": 3000,
    "NumAttributes": 27,
    "DateDonated": "2011-07-27",
    "MissingValues": 0,
    "URLFolder": "../machine-learning-databases/00214/",
    "URLReadme": "#",
    "HighestAccuracy": 0,
    "RelevantInfo": "1. Protocol:\r\n   Seven male and three female subjects (age 25 to 30), who have experienced aggression in scenarios such\r\n   as physical fighting, took part in the experiment. Throughout 20 individual experiments, each subject\r\n   had to perform ten normal and ten aggressive activities. Regarding the rights of the subjects involved,\r\n   ethical regulations have been followed based on the code of ethics of the British psychological society,\r\n   which explains the ethical legislations to conduct statistical experiments using human subjects. For safety\r\n   precaution issues, boxing hand wraps have been given to the subjects, and for the warm up the subjects\r\n   were instructed to familiarise with the bag by having a number of trial runs. The subjects were aware that\r\n   since their involvement in this series of experiments was voluntary, it was made clear that they could\r\n   withdraw at any time from the study.\r\n\r\n2. Instrumentation:\r\n   The Essex robotic arena was the main experimental hall where the data collection took place. With area\r\n   4x5.5m, the ten subjects expressed normal and aggressive physical activities at random locations. For the\r\n   normal actions, a human partner has been used as a focus target attracting the attention from the subjects\r\n   so as to perform more realistic activity. For the aggressive actions, the subjects made use of a professional\r\n   kick-boxing standing bag, 1.75m tall, with a human figure drawn on its body. The bag has cylindrical shape\r\n   made from soft material, which could bounce when hit. All the activities have been recorded from random\r\n   starting positions so that to have a variety of spatial 3D data. The subjects\u00e2\u20ac\u2122 performance has been recorded\r\n   by the Vicon\u00e2\u20ac\u2122s nine ubiquitous cameras, interfacing human activity with spatial coordinate points. Based on\r\n   this context, the data acquisition process involved four reflectable markers placed on the forearms (elbows\r\n   and wrists), four on the forelegs (knees and ankles), and one on the top of the head.\r\n\r\n3. Data Setup:\r\n   Each experimental trial has been taken separately for each physical activity. The duration of each action\r\n   was approximately ~10 seconds per subject, which corresponds to a time series of ~3000 samples, with\r\n   sampling frequency of 200Hz. Within this performance time, approximately 15 action trajectories were\r\n   extracted counting in average 15 normal (ex: handshaking), and 15 aggressive (ex: punching) actions.",
    "Source": "Theo Theodoridis\r\nSchool of Computer Science and Electronic Engineering\r\nUniversity of Essex\r\nWivenhoe Park, Colchester, CO4 3SQ, UK\r\nttheod@gmail.com\r\nhttp://sites.google.com/site/ttheod/",
    "Acknowledgements": "",
    "Area": "Physical",
    "RelevantPapers": "1. T. Theodoridis and H. Hu, Classifying Aggressive Actions of 3D Human Models Using\r\n   Dynamic ANNs for Mobile Robot Surveillance, IEEE International Conference on Robotics\r\n   and Biomimetics (Robio-2007), Dec. 15-18, 2007, pp. 371-376.\r\n\r\n2. T. Theodoridis, A. Agapitos, H. Hu, and S. M. Lucas, Ubiquitous Robotics in Physical\r\n   Human Action Recognition: A Comparison Between Dynamic ANNs and GP, IEEE International\r\n   Conference on Robotics and Automation (ICRA-2008), May 19-23, 2008, pp. 3064-3069.\r\n\r\n3. T. Theodoridis and H. Hu, A Fuzzy-Convolution Model for Physical Action and Behaviour\r\n   Pattern Recognition of 3D Time Series, IEEE Int. Conference on Robotics and Biomimetics\r\n   (Robio-2008), Feb. 21-26, 2009, pp. 407-412.\r\n\r\n4. T. Theodoridis, A. Agapitos, H. Hu, and S. M. Lucas, Mechanical Feature Attributes for\r\n   Modeling and Pattern Classification of Physical Activities, IEEE International Conference\r\n   in Information and Automation (ICIA-2009), June 22-24, 2009, pp. 528-533.\r\n\r\n5. T. Theodoridis, A. Agapitos, H. Hu, and S. M. Lucas, A QA-TSK Fuzzy Model versus Evolutionary\r\n   Decision Trees Towards Nonlinear Action Pattern Recognition, IEEE International Conference in\r\n   Information and Automation (ICIA-2010), June 20-23, 2010, pp. 1813-1818.\r\n\r\n6. T. Theodoridis, P. Theodorakopoulos, and H. Hu, Evolving Aggressive Biomechanical Models with\r\n   Genetic Programming, IEEE/RSJ International Conference on Intelligent Robots and Systems,\r\n   (IROS-2010), Oct. 18-22, 2010, pp. 2495-2500.\r\n\r\n7. T. Theodoridis, A. Agapitos, and H. Hu, A Gaussian Groundplan Projection Area Model for\r\n   Evolving Probabilistic Classifiers, GECCO Genetic and Evolutionary Computation Conference\r\n   (GECCO-2011), Jul. 12-16, 2011, pp. 1339-1346.",
    "AttributeInfo": "Each file in the dataset contains in overall 28 columns (the 1st is a counter), and is organised as follows:\r\n\r\n+---------+-------+---------------+---------------------+---------------------+---------------------+\r\n| Segment | Head  |     L-Arm     |        R-Arm        |        L-Leg        |        R-Leg        |\r\n+---------+-------+-------+-------+----------+----------+----------+----------+----------+----------+\r\n| Marker  | m1    | m2    | m3    | m4       | m5       | m6       | m7       | m8       | m9       |\r\n| Coords  | x y z | x y z | x y z | x  y  z  | x  y  z  | x  y  z  | x  y  z  | x  y  z  | x  y  z  |\r\n| Column  | 1,2,3 | 4,5,6 | 7,8,9 | 10,11,12 | 13,14,15 | 16,17,18 | 19,20,21 | 22,23,24 | 25,26,27 |\r\n+---------+-------+-------+-------+----------+----------+----------+----------+----------+----------+\r\n\r\nSegment: A segment defines a body segment or limb.\r\n         - Head\r\n\t - Left arm (L-Arm)\r\n\t - Right arm (R-Arm)\r\n\t - Left leg (L-Leg)\r\n\t - Right leg (R-Leg)\r\n\r\nMarker:  A pair of markers (except the head) is attached at each body segment for 3D data acquisition.\r\n\t - Arm markers: wrist (WRS), elbow (ELB)\r\n\t - Leg markers: ankle (ANK), knee (KNE)\r\n\r\nCoords:  The 3 coordinates (x,y,z) define the 3D position of each marker in space.\r\n\t - x: The x coordinate\r\n\t - y: The y coordinate\r\n\t - z: The z coordinate",
    "FormatType": "Matrix",
    "NumHits": 9
}