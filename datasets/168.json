{
    "ID": 168,
    "Name": "Dexter",
    "Abstract": "DEXTER is a text classification problem in a bag-of-word representation. This is a two-class classification problem with sparse continuous input variables. This dataset is one of five datasets of the NIPS 2003 feature selection challenge.\r\n",
    "Types": "Multivariate",
    "Task": "Classification",
    "AttributeTypes": "Integer",
    "NumInstances": 2600,
    "NumAttributes": 20000,
    "DateDonated": "2008-02-29",
    "MissingValues": 0,
    "URLFolder": "../machine-learning-databases/dexter/",
    "URLReadme": "../machine-learning-databases/dexter/Dataset.pdf",
    "HighestAccuracy": 0,
    "RelevantInfo": "The original data were formatted by Thorsten Joachims in the \u201cbag-of-words\u201d representation. There were 9947 features (of which 2562 are always zeros for all the examples) representing frequencies of occurrence of word stems in text. The task is to learn which Reuters articles are about 'corporate acquisitions'. We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized.\r\n \r\nDEXTER -- Positive ex. -- Negative ex. -- Total\t\t   \r\nTraining set --150 -- 150 -- 300\t\t   \r\nValidation set -- 150 -- 150 -- 300\t\t   \r\nTest set -- 1000 -- 1000 -- 2000\t\t   \r\nAll -- 1300 -- 1300 -- 2600\t\t \r\n\r\nNumber of variables/features/attributes:\r\nReal: 9947\r\nProbes: 10053\r\nTotal: 20000\r\n\r\nThis dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website http://www.nipsfsc.ecs.soton.ac.uk/ is still open for post-challenge submissions. Information about other related challenges are found at: http://clopinet.com/challenges. The CLOP package includes sample code to process these data: http://clopinet.com/CLOP.\r\n\r\nAll details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, http://www.nipsfsc.ecs.soton.ac.uk/papers/NIPS2003-Datasets.pdf (also included in the dataset archive). Such information was made available only after the end of the challenge.\r\n\r\nThe data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: http://www.nipsfsc.ecs.soton.ac.uk/.\r\n\r\nThe data are in the following format:\r\ndataname.param: Parameters and statistics about the data\r\ndataname.feat: Identities of the features (withheld, to avoid biasing feature selection).\r\ndataname_train.data: Training set (a sparse matrix, patterns in lines, features in columns: feature number followed by value).  \r\ndataname_valid.data: Validation set.    \r\ndataname_test.data: Test set. \r\ndataname_train.labels: Labels (truth values of the classes) for training examples.   \r\ndataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).\r\ndataname_test.labels: Test set labels  (withheld, so the data can still be use as a benchmark).",
    "Source": "a.\tOriginal owners\r\nThe original data set we used is a subset of the well-known Reuters text categorization benchmark. The data was originally collected and labeled by Carnegie Group, Inc. and Reuters, Ltd. in the course of developing the CONSTRUE text categorization system.  It is hosted by the UCI KDD repository: http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html. David D. Lewis is hosting valuable resources about this data (see http://www.daviddlewis.com/resources/testcollections/reuters21578/). We used the \u201ccorporate acquisition\u201d text classification class pre-processed by Thorsten Joachims <thorsten@joachims.org>. The data is one of the examples of the software package SVM-Light., see http://svmlight.joachims.org/. The example can be downloaded from ftp://ftp-ai.cs.uni-dortmund.de/pub/Users/thorsten/svm_light/examples/example1.tar.gz.\r\n\r\nb.\tDonor of database\r\nThis version of the database was prepared for the NIPS 2003 variable and feature selection benchmark by Isabelle Guyon, 955 Creston Road, Berkeley, CA 94708, USA (isabelle@clopinet.com).\r\n",
    "Acknowledgements": "Isabelle Guyon, Steve R. Gunn, Asa Ben-Hur, Gideon Dror, 2004. Result analysis of the NIPS 2003 feature selection challenge. In: NIPS. http://books.nips.cc/papers/files/nips17/NIPS2004_0194.pdf.",
    "Area": "Other",
    "RelevantPapers": "The best challenge entrants wrote papers collected in the book:\r\nIsabelle Guyon, Steve Gunn, Masoud Nikravesh, Lofti Zadeh (Eds.), Feature Extraction, Foundations and Applications. Studies in Fuzziness and Soft Computing. Physica-Verlag, Springer. http://clopinet.com/fextract-book/\r\n\r\nSee also:\r\nIsabelle Guyon, et al, 2007. Competitive baseline methods set new standards for the NIPS 2003 feature selection benchmark. Pattern Recognition Letters 28 (2007) 1438\u20131444.\r\nand the associated technical report:\r\nIsabelle Guyon, et al. 2006. Feature selection with the CLOP package. Technical Report. http://clopinet.com/isabelle/Projects/ETH/TM-fextract-class.pdf.\r\n",
    "AttributeInfo": "We do not provide feature information to avoid biasing feature selection.",
    "FormatType": "Matrix",
    "NumHits": 9
}